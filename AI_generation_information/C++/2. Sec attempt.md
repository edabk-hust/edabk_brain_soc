# The second attempt from bare-metal Python code to C

## USER
I develop the followin CNN model in a python bare metal implementaiton for the mnist dataset:

The CNN model is:
```python
model =  models.Sequential()
model.add(layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((4, 4)))
model.add(layers.Conv2D(8, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(10, dtype='float16')) 

While the Python code is:
import pandas as pd
import numpy as np

# Replace 'filename.csv' with the actual file path of your dataset
df = pd.read_csv('mnist_train.csv')

# Extract labels (first column)
train_labels = df.iloc[:, 0].values

# Extract pixel values and reshape them into 28x28 images
train_images = df.iloc[:, 1:].values.reshape(-1, 28, 28)

# Replace 'filename.csv' with the actual file path of your dataset
df2 = pd.read_csv('mnist_test.csv')

# Extract labels (first column)
test_labels = df2.iloc[:, 0].values

# Extract pixel values and reshape them into 28x28 images
test_images = df2.iloc[:, 1:].values.reshape(-1, 28, 28)

train_images = train_images.astype('float16')
test_images = test_images.astype('float16')

train_images, test_images = train_images / 255.0, test_images / 255.0

print(test_images.dtype)
print(train_images.dtype)

# Load weights and biases from .npy files
weights_conv1 = np.load('weights_conv1.npy')
biases_conv1 = np.load('biases_conv1.npy')
weights_conv2 = np.load('weights_conv2.npy')
biases_conv2 = np.load('biases_conv2.npy')
"""weights_conv3 = np.load('weights_conv3.npy')
biases_conv3 = np.load('biases_conv3.npy')
weights_dense1 = np.load('weights_dense1.npy')
biases_dense1 = np.load('biases_dense1.npy')"""
weights_dense2 = np.load('weights_dense2.npy')
biases_dense2 = np.load('biases_dense2.npy')
 


# define activation functions
def relu(x):
    return np.maximum(0, x)

def softmax(x):
    exps = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return exps / np.sum(exps, axis=-1, keepdims=True)

# define forward pass functions
def conv2d_forward(X, W, b):
    # X - input, W - weights, b - bias
    h_filter, w_filter, d_filter, n_filters = W.shape
    h, w, d = X.shape
    out = np.zeros((h - h_filter + 1, w - w_filter + 1, n_filters))
    for i in range(h - h_filter + 1):
        for j in range(w - w_filter + 1):
            for k in range(n_filters):
                out[i, j, k] = np.sum(X[i:i+h_filter, j:j+w_filter] * W[:, :, :, k]) + b[k]
    return out

def maxpool2d_forward(X, pool_size):
    h, w, d = X.shape
    h_out = h // pool_size
    w_out = w // pool_size
    out = np.zeros((h_out, w_out, d))
    for i in range(h_out):
        for j in range(w_out):
            for k in range(d):
                out[i, j, k] = np.max(X[i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size, k])
    return out

def flatten(X):
    return X.flatten()

def dense_forward(X, W, b):
    return np.dot(W.T, X) + b



# Assuming weights and biases have been loaded as mentioned before
# Modify the forward function to take these parameters as arguments

def forward(X, W_conv1, b_conv1, W_conv2, b_conv2, W_dense2, b_dense2):
    out = conv2d_forward(X, W_conv1, b_conv1)
    out = relu(out)
    out = maxpool2d_forward(out, 4)
    out = conv2d_forward(out, W_conv2, b_conv2)
    out = relu(out)
    out = maxpool2d_forward(out, 2)
    """   out = conv2d_forward(out, W_conv3, b_conv3)
    out = relu(out)
    out = maxpool2d_forward(out, 2)
  
    out = dense_forward(out, W_dense1, b_dense1)
    out = relu(out)"""
    out = flatten(out)
    out = dense_forward(out, W_dense2, b_dense2)
    out = softmax(out)
    return out

# Call the function with a single image from the test dataset and the weights and biases

image_index = 96
single_image = test_images[image_index]  # assuming test_images is your test dataset

# Ensure that the single image has the right shape (28, 28, 1)
single_image = np.reshape(single_image, (28, 28, 1))

output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_dense2, biases_dense2)

print(np.argmax(output))

import matplotlib.pyplot as plt



print("Test image shape:", test_images[image_index].shape)  # (28, 28)
print("Test label:", test_labels[image_index])  # The label (0 to 9)

x = test_images[image_index]

x = x.reshape(28, 28, 1)



# Assuming you already have 'x' containing the image data

# Reshape the image back to 28x28 (if necessary)
if len(x.shape) == 3:
    x = x.reshape(28, 28)

# Display the image using matplotlib
"""plt.imshow(x, cmap='gray')
plt.axis('off')  # Turn off axis ticks and labels
plt.show()"""

correct_predictions = 0
#(x_train, y_train), (x_test, y_test) = mnist.load_data() #%%This was doing before
# iterate over the test set
#for i in range(len(x_test)):

for i in range(1000):
    # prepare the input
    x = test_images[i].astype(np.float16)

    # Ensure that the single image has the right shape (28, 28, 1)
    single_image = np.reshape(x, (28, 28, 1))

    #output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_conv3, biases_conv3, weights_dense1, biases_dense1, weights_dense2, biases_dense2)
    output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_dense2, biases_dense2)

    # Find the index of the maximum value
    prediction = np.argmax(output)

    # compare the prediction with the actual label
    #actual_label = np.argmax(test_labels[i])
    actual_label = test_labels[i]

    if prediction == actual_label:
        correct_predictions += 1

# calculate the accuracy
accuracy = correct_predictions / 1000
print("The accuracy of the forward_pass function is:", accuracy)
```
Rewrite the python code on a C code:
Weights and biases will be load as a bin data.

## ASSISTANT

Below is a simplified bare-metal version of your python code implemented in C. Keep in mind this is a simple C implementation and some functions like Conv2D and MaxPooling2D are simplified and do not account for padding, stride or other complex scenarios, but it should give you a good starting point. I also assume that weights and biases are saved as binary files in the form of 1D arrays, and it's the responsibility of the programmer to ensure that they are loaded correctly according to their original shapes.
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// Let's assume that the maximum dimensions of our layers is 28
#define MAX_DIM 28
#define NUM_CLASSES 10

// The weights and biases are all defined as global variables
float weights_conv1[3 * 3 * 1 * 4];
float biases_conv1[4];
float weights_conv2[3 * 3 * 4 * 8];
float biases_conv2[8];
float weights_dense2[4 * 8 * 10];
float biases_dense2[10];

// load weights and biases from binary files
void load_weights_biases() {
    FILE *file;
    file = fopen("weights_conv1.bin", "rb");
    fread(weights_conv1, sizeof(float), 3 * 3 * 1 * 4, file);
    fclose(file);

    file = fopen("biases_conv1.bin", "rb");
    fread(biases_conv1, sizeof(float), 4, file);
    fclose(file);

    file = fopen("weights_conv2.bin", "rb");
    fread(weights_conv2, sizeof(float), 3 * 3 * 4 * 8, file);
    fclose(file);

    file = fopen("biases_conv2.bin", "rb");
    fread(biases_conv2, sizeof(float), 8, file);
    fclose(file);

    file = fopen("weights_dense2.bin", "rb");
    fread(weights_dense2, sizeof(float), 4 * 8 * 10, file);
    fclose(file);

    file = fopen("biases_dense2.bin", "rb");
    fread(biases_dense2, sizeof(float), 10, file);
    fclose(file);
}

float relu(float x) {
    return fmaxf(0, x);
}

float* softmax(float *x, int length) {
    float max = x[0];
    for(int i = 0; i < length; i++)
        if(x[i] > max)
            max = x[i];

    float sum = 0;
    for(int i = 0; i < length; i++) {
        x[i] = exp(x[i] - max);
        sum += x[i];
    }

    for(int i = 0; i < length; i++)
        x[i] /= sum;

    return x;
}

void forward_pass(float* image) {
    // Assume here that the image has a size of 28x28x1 and weights and biases are already loaded

    // First Conv2D layer: input is 28x28x1, filter is 3x3x1x4
    // It results in a 26x26x4 output (we are assuming VALID padding)
    float conv1[26][26][4];
    for(int i = 0; i < 26; i++)
        for(int j = 0; j < 26; j++)
            for(int k = 0; k < 4; k++) {
                conv1[i][j][k] = 0;
                // Convolution operation
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        conv1[i][j][k] += image[(i+di)*28 + (j+dj)] * weights_conv1[(di*3 + dj)*4 + k];
                conv1[i][j][k] += biases_conv1[k];
                // ReLU activation
                conv1[i][j][k] = relu(conv1[i][j][k]);
            }

    // ... Implement the rest of the forward pass following this pattern ...
}

int main() {
    // Load the weights and biases from the binary files
    load_weights_biases();

    // Assume here that you have loaded a MNIST image into the 'image' array
    float image[28*28];

    // Call the forward pass function
    forward_pass(image);

    return 0;
}
```
Remember to also include error checking and handle memory management carefully when working with C. This code is quite simplified and omits many practical considerations for the sake of clarity.

## USER
mplement the whole forward function:
```
void forward_pass(float* image) {
    // Assume here that the image has a size of 28x28x1 and weights and biases are already loaded

    // First Conv2D layer: input is 28x28x1, filter is 3x3x1x4
    // It results in a 26x26x4 output (we are assuming VALID padding)
    float conv1[26][26][4];
    for(int i = 0; i < 26; i++)
        for(int j = 0; j < 26; j++)
            for(int k = 0; k < 4; k++) {
                conv1[i][j][k] = 0;
                // Convolution operation
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        conv1[i][j][k] += image[(i+di)*28 + (j+dj)] * weights_conv1[(di*3 + dj)*4 + k];
                conv1[i][j][k] += biases_conv1[k];
                // ReLU activation
                conv1[i][j][k] = relu(conv1[i][j][k]);
            }

    // ... Implement the rest of the forward pass following this pattern ...
}
```

## ASSISTANT
Sure, let's continue from where we left off:
```c
void forward_pass(float* image) {
    // Assume here that the image has a size of 28x28x1 and weights and biases are already loaded

    // First Conv2D layer: input is 28x28x1, filter is 3x3x1x4
    // It results in a 26x26x4 output (we are assuming VALID padding)
    float conv1[26][26][4];
    for(int i = 0; i < 26; i++)
        for(int j = 0; j < 26; j++)
            for(int k = 0; k < 4; k++) {
                conv1[i][j][k] = 0;
                // Convolution operation
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        conv1[i][j][k] += image[(i+di)*28 + (j+dj)] * weights_conv1[(di*3 + dj)*4 + k];
                conv1[i][j][k] += biases_conv1[k];
                // ReLU activation
                conv1[i][j][k] = relu(conv1[i][j][k]);
            }

    // First MaxPooling layer: input is 26x26x4, pool size is 4
    // It results in a 6x6x4 output
    float maxpool1[6][6][4];
    for(int i = 0; i < 6; i++)
        for(int j = 0; j < 6; j++)
            for(int k = 0; k < 4; k++) {
                maxpool1[i][j][k] = 0;
                for(int di = 0; di < 4; di++)
                    for(int dj = 0; dj < 4; dj++)
                        maxpool1[i][j][k] = fmaxf(maxpool1[i][j][k], conv1[i*4+di][j*4+dj][k]);
            }

    // Second Conv2D layer: input is 6x6x4, filter is 3x3x4x8
    // It results in a 4x4x8 output
    float conv2[4][4][8];
    for(int i = 0; i < 4; i++)
        for(int j = 0; j < 4; j++)
            for(int k = 0; k < 8; k++) {
                conv2[i][j][k] = 0;
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        for(int dk = 0; dk < 4; dk++)
                            conv2[i][j][k] += maxpool1[i+di][j+dj][dk] * weights_conv2[((di*3+dj)*4+dk)*8+k];
                conv2[i][j][k] += biases_conv2[k];
                conv2[i][j][k] = relu(conv2[i][j][k]);
            }

    // Second MaxPooling layer: input is 4x4x8, pool size is 2
    // It results in a 2x2x8 output
    float maxpool2[2][2][8];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++) {
                maxpool2[i][j][k] = 0;
                for(int di = 0; di < 2; di++)
                    for(int dj = 0; dj < 2; dj++)
                        maxpool2[i][j][k] = fmaxf(maxpool2[i][j][k], conv2[i*2+di][j*2+dj][k]);
            }

    // Flatten layer: input is 2x2x8
    // It results in a 32-length 1D array
    float flatten[32];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++)
                flatten[i*2*8 + j*8 + k] = maxpool2[i][j][k];

    // Dense layer: input is a 32-length 1D array, weights are 32x10
    // It results in a 10-length 1D array
    float dense[10];
    for(int i = 0; i < 10; i++) {
        dense[i] = 0;
        for(int j = 0; j < 32; j++)
            dense[i] += flatten[j] * weights_dense2[j*10+i];
        dense[i] += biases_dense2[i];
    }

    // Softmax activation
    float* softmax_output = softmax(dense, 10);

    // Print the output
    for(int i = 0; i < 10; i++)
        printf("%f ", softmax_output[i]);
    printf("\n");
}
```

## USER
Develop the fmaxf function

## ASSISTANT
Sure, the fmaxf function returns the maximum value of two floating point numbers. Here's a basic implementation of fmaxf in C:
```c
float fmaxf(float a, float b) {
    if(a > b) {
        return a;
    } else {
        return b;
    }
}
```

This function takes two floating point numbers as input and returns the larger of the two. If the numbers are equal, it will simply return the first one. Please note that this implementation doesn't handle special cases like NaN (Not a Number) values. If you want your fmaxf function to behave exactly like the standard C library's fmaxf, you'll need to add additional checks to handle these cases.

## USER
the last printf of the forward functions are the output of my 10 nodes?

## ASSISTANT
Yes, you're correct. In the forward_pass function I provided, the printf statement in the end is used to print out the output of the final Dense layer, which is the output of your 10 nodes.

Each element in the softmax_output array corresponds to the prediction score for one class (digit) from 0 to 9. This prediction score is a probability value obtained after applying the softmax function, which indicates the likelihood that the input image represents the corresponding class.

So, if you want to get the predicted class, you can simply find the index of the maximum value in the softmax_output array:
```c
int predicted_class = 0;
for (int i = 1; i < 10; ++i) {
    if (softmax_output[i] > softmax_output[predicted_class]) {
        predicted_class = i;
    }
}
printf("Predicted class: %d\n", predicted_class);
```
This will give you the digit that your model predicts for the input image.

## USER
Create a function that convert the forward function into one hot output

## ASSISTANT
Sure, if you want to get a one-hot encoded version of the model's output, you'll have to find the index with the maximum probability (as this represents the predicted class), and then create an array where all elements are zero except for the element at that index, which should be one.

Here's how you can modify the forward_pass function to output a one-hot encoded array:
```c
void forward_pass(float* image, int* one_hot_output) {
    // ... The rest of your forward_pass function goes here ...

    // One-hot output generation
    int max_index = 0;
    for (int i = 1; i < 10; ++i) {
        if (softmax_output[i] > softmax_output[max_index]) {
            max_index = i;
        }
    }

    // Set all elements to zero
    for (int i = 0; i < 10; ++i) {
        one_hot_output[i] = 0;
    }

    // Set the element at max_index to 1
    one_hot_output[max_index] = 1;
}
```
This modification will give you a one-hot encoded output where all elements are zero except for the predicted class, which is set to one. The one_hot_output array must be preallocated with size 10 before calling forward_pass.

Please note that the one-hot encoded output should be used carefully. It has a high level of certainty (it's completely sure about its prediction) which is often not a realistic representation of a model's confidence. The raw output of the model (softmax output) gives you a better understanding of how sure the model is about its predictions.

## USER

This is my C code to execute the forward function, the code works correctly:
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// Let's assume that the maximum dimensions of our layers is 28
#define MAX_DIM 28
#define NUM_CLASSES 10

// The weights and biases are all defined as global variables
float weights_conv1[3 * 3 * 1 * 4];
float biases_conv1[4];
float weights_conv2[3 * 3 * 4 * 8];
float biases_conv2[8];
float weights_dense2[4 * 8 * 10];
float biases_dense2[10];

float fmaxf(float a, float b) {
    if(a > b) {
        return a;
    } else {
        return b;
    }
}

// load weights and biases from binary files
void load_weights_biases() {
    FILE *file;
    file = fopen("weights_conv1.bin", "rb");
    fread(weights_conv1, sizeof(float), 3 * 3 * 1 * 4, file);
    fclose(file);

    file = fopen("biases_conv1.bin", "rb");
    fread(biases_conv1, sizeof(float), 4, file);
    fclose(file);

    file = fopen("weights_conv2.bin", "rb");
    fread(weights_conv2, sizeof(float), 3 * 3 * 4 * 8, file);
    fclose(file);

    file = fopen("biases_conv2.bin", "rb");
    fread(biases_conv2, sizeof(float), 8, file);
    fclose(file);

    file = fopen("weights_dense2.bin", "rb");
    fread(weights_dense2, sizeof(float), 4 * 8 * 10, file);
    fclose(file);

    file = fopen("biases_dense2.bin", "rb");
    fread(biases_dense2, sizeof(float), 10, file);
    fclose(file);
}

float relu(float x) {
    return fmaxf(0, x);
}

float* softmax(float *x, int length) {
    float max = x[0];
    for(int i = 0; i < length; i++)
        if(x[i] > max)
            max = x[i];

    float sum = 0;
    for(int i = 0; i < length; i++) {
        x[i] = exp(x[i] - max);
        sum += x[i];
    }

    for(int i = 0; i < length; i++)
        x[i] /= sum;

    return x;
}

void forward_pass(float* image, int* one_hot_output) {
    // Assume here that the image has a size of 28x28x1 and weights and biases are already loaded

    // First Conv2D layer: input is 28x28x1, filter is 3x3x1x4
    // It results in a 26x26x4 output (we are assuming VALID padding)
    float conv1[26][26][4];
    for(int i = 0; i < 26; i++)
        for(int j = 0; j < 26; j++)
            for(int k = 0; k < 4; k++) {
                conv1[i][j][k] = 0;
                // Convolution operation
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        conv1[i][j][k] += image[(i+di)*28 + (j+dj)] * weights_conv1[(di*3 + dj)*4 + k];
                conv1[i][j][k] += biases_conv1[k];
                // ReLU activation
                conv1[i][j][k] = relu(conv1[i][j][k]);
            }

    // First MaxPooling layer: input is 26x26x4, pool size is 4
    // It results in a 6x6x4 output
    float maxpool1[6][6][4];
    for(int i = 0; i < 6; i++)
        for(int j = 0; j < 6; j++)
            for(int k = 0; k < 4; k++) {
                maxpool1[i][j][k] = 0;
                for(int di = 0; di < 4; di++)
                    for(int dj = 0; dj < 4; dj++)
                        maxpool1[i][j][k] = fmaxf(maxpool1[i][j][k], conv1[i*4+di][j*4+dj][k]);
            }

    // Second Conv2D layer: input is 6x6x4, filter is 3x3x4x8
    // It results in a 4x4x8 output
    float conv2[4][4][8];
    for(int i = 0; i < 4; i++)
        for(int j = 0; j < 4; j++)
            for(int k = 0; k < 8; k++) {
                conv2[i][j][k] = 0;
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        for(int dk = 0; dk < 4; dk++)
                            conv2[i][j][k] += maxpool1[i+di][j+dj][dk] * weights_conv2[((di*3+dj)*4+dk)*8+k];
                conv2[i][j][k] += biases_conv2[k];
                conv2[i][j][k] = relu(conv2[i][j][k]);
            }

    // Second MaxPooling layer: input is 4x4x8, pool size is 2
    // It results in a 2x2x8 output
    float maxpool2[2][2][8];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++) {
                maxpool2[i][j][k] = 0;
                for(int di = 0; di < 2; di++)
                    for(int dj = 0; dj < 2; dj++)
                        maxpool2[i][j][k] = fmaxf(maxpool2[i][j][k], conv2[i*2+di][j*2+dj][k]);
            }

    // Flatten layer: input is 2x2x8
    // It results in a 32-length 1D array
    float flatten[32];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++)
                flatten[i*2*8 + j*8 + k] = maxpool2[i][j][k];

    // Dense layer: input is a 32-length 1D array, weights are 32x10
    // It results in a 10-length 1D array
    float dense[10];
    for(int i = 0; i < 10; i++) {
        dense[i] = 0;
        for(int j = 0; j < 32; j++)
            dense[i] += flatten[j] * weights_dense2[j*10+i];
        dense[i] += biases_dense2[i];
    }

    // Softmax activation
    float* softmax_output = softmax(dense, 10);

    // One-hot output generation
    int max_index = 0;
    for (int i = 1; i < 10; ++i) {
        if (softmax_output[i] > softmax_output[max_index]) {
            max_index = i;
        }
    }

    // Set all elements to zero
    for (int i = 0; i < 10; ++i) {
        one_hot_output[i] = 0;
    }

    // Set the element at max_index to 1
    one_hot_output[max_index] = 1;

    // Print the output
    printf("C forward function label = %d\n", max_index);
}

int main() {
    FILE *file;
    int one_Hot_output[10];
    float single_image[28][28][1];
    int test_label;

    file = fopen("test_images.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open file.\n");
        return 1;
    }

    fread(single_image, sizeof(float), 28*28*1, file);

    printf("Single image declaration finih");

    
    file = fopen("train_labels.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open file.\n");
        return 1;
    }

    fread(&test_label, sizeof(int),1, file);

    printf("Label image declaration finih\n\n");

    // Load the weights and biases from the binary files
    load_weights_biases();

    // Assume here that you have loaded a MNIST image into the 'image' array
    float image[28*28];

    // Call the forward pass function
    forward_pass(image,one_Hot_output);
    printf("Test label = %d",test_label);
    return 0;
}
```
To save the bin file I uses the following python code:
```python
import pandas as pd
import numpy as np

# Replace 'filename.csv' with the actual file path of your dataset
df = pd.read_csv('mnist_train.csv')

# Extract labels (first column)
train_labels = df.iloc[:, 0].values

# Extract pixel values and reshape them into 28x28 images
train_images = df.iloc[:, 1:].values.reshape(-1, 28, 28)

# Replace 'filename.csv' with the actual file path of your dataset
df2 = pd.read_csv('mnist_test.csv')

# Extract labels (first column)
test_labels = df2.iloc[:, 0].values

# Extract pixel values and reshape them into 28x28 images
test_images = df2.iloc[:, 1:].values.reshape(-1, 28, 28)

train_images = train_images.astype('float16')
test_images = test_images.astype('float16')

train_images, test_images = train_images / 255.0, test_images / 255.0

image_index = 96

test_images[image_index].tofile('test_images.bin')
train_labels[image_index].tofile('train_labels.bin')
```

Generate the python code to Save all test images and test labels. and generate the C code that read all images and labels

## ASSISTANT
Python code to save all test images and labels:
```python
import pandas as pd
import numpy as np

df2 = pd.read_csv('mnist_test.csv')

test_labels = df2.iloc[:, 0].values
test_images = df2.iloc[:, 1:].values.reshape(-1, 28, 28)

test_images = test_images.astype('float16')
test_images = test_images / 255.0

# Save all images and labels
test_images.tofile('test_images.bin')
test_labels.tofile('test_labels.bin')

```
C code to read all images and labels:
```c
#include <stdio.h>
#include <stdlib.h>

#define IMAGE_SIZE 28*28
#define NUM_IMAGES 10000  // Assuming you have 10000 images and labels in the test set

int main() {
    FILE *file;
    float images[NUM_IMAGES][IMAGE_SIZE];
    int labels[NUM_IMAGES];

    file = fopen("test_images.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open image file.\n");
        return 1;
    }

    for (int i = 0; i < NUM_IMAGES; ++i) {
        fread(images[i], sizeof(float), IMAGE_SIZE, file);
    }

    fclose(file);

    file = fopen("test_labels.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open label file.\n");
        return 1;
    }

    fread(labels, sizeof(int), NUM_IMAGES, file);

    fclose(file);

    printf("Loaded %d images and labels.\n", NUM_IMAGES);

    // Now you can use the images and labels in your forward_pass function
    // You may need to adjust the forward_pass function to accept a 2D image instead of 1D

    return 0;
}

```
his C code reads all the images into a 2D array (images), where each row is a separate image represented as a 1D array (flattened 28x28 image). The corresponding labels are stored in the labels array.

Note: Update the NUM_IMAGES constant to match the number of images in your test set. In this example, I assumed that there are 10000 images in the test set.

## USER
Based on the C code create a function that compare the output of the forward function and the label:

#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// Let's assume that the maximum dimensions of our layers is 28
#define MAX_DIM 28
#define NUM_CLASSES 10

#define IMAGE_SIZE 28*28
#define NUM_IMAGES 10000  // Assuming you have 10000 images and labels in the test set


// The weights and biases are all defined as global variables
float weights_conv1[3 * 3 * 1 * 4];
float biases_conv1[4];
float weights_conv2[3 * 3 * 4 * 8];
float biases_conv2[8];
float weights_dense2[4 * 8 * 10];
float biases_dense2[10];

float fmaxf(float a, float b) {
    if(a > b) {
        return a;
    } else {
        return b;
    }
}



// load weights and biases from binary files
void load_weights_biases() {
    FILE *file;
    file = fopen("weights_conv1.bin", "rb");
    fread(weights_conv1, sizeof(float), 3 * 3 * 1 * 4, file);
    fclose(file);

    file = fopen("biases_conv1.bin", "rb");
    fread(biases_conv1, sizeof(float), 4, file);
    fclose(file);

    file = fopen("weights_conv2.bin", "rb");
    fread(weights_conv2, sizeof(float), 3 * 3 * 4 * 8, file);
    fclose(file);

    file = fopen("biases_conv2.bin", "rb");
    fread(biases_conv2, sizeof(float), 8, file);
    fclose(file);

    file = fopen("weights_dense2.bin", "rb");
    fread(weights_dense2, sizeof(float), 4 * 8 * 10, file);
    fclose(file);

    file = fopen("biases_dense2.bin", "rb");
    fread(biases_dense2, sizeof(float), 10, file);
    fclose(file);
}

float relu(float x) {
    return fmaxf(0, x);
}

float* softmax(float *x, int length) {
    float max = x[0];
    for(int i = 0; i < length; i++)
        if(x[i] > max)
            max = x[i];

    float sum = 0;
    for(int i = 0; i < length; i++) {
        x[i] = exp(x[i] - max);
        sum += x[i];
    }

    for(int i = 0; i < length; i++)
        x[i] /= sum;

    return x;
}

int forward_pass(float* image, int* one_hot_output) {
    // Assume here that the image has a size of 28x28x1 and weights and biases are already loaded

    // First Conv2D layer: input is 28x28x1, filter is 3x3x1x4
    // It results in a 26x26x4 output (we are assuming VALID padding)
    float conv1[26][26][4];
    for(int i = 0; i < 26; i++)
        for(int j = 0; j < 26; j++)
            for(int k = 0; k < 4; k++) {
                conv1[i][j][k] = 0;
                // Convolution operation
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        conv1[i][j][k] += image[(i+di)*28 + (j+dj)] * weights_conv1[(di*3 + dj)*4 + k];
                conv1[i][j][k] += biases_conv1[k];
                // ReLU activation
                conv1[i][j][k] = relu(conv1[i][j][k]);
            }

    // First MaxPooling layer: input is 26x26x4, pool size is 4
    // It results in a 6x6x4 output
    float maxpool1[6][6][4];
    for(int i = 0; i < 6; i++)
        for(int j = 0; j < 6; j++)
            for(int k = 0; k < 4; k++) {
                maxpool1[i][j][k] = 0;
                for(int di = 0; di < 4; di++)
                    for(int dj = 0; dj < 4; dj++)
                        maxpool1[i][j][k] = fmaxf(maxpool1[i][j][k], conv1[i*4+di][j*4+dj][k]);
            }

    // Second Conv2D layer: input is 6x6x4, filter is 3x3x4x8
    // It results in a 4x4x8 output
    float conv2[4][4][8];
    for(int i = 0; i < 4; i++)
        for(int j = 0; j < 4; j++)
            for(int k = 0; k < 8; k++) {
                conv2[i][j][k] = 0;
                for(int di = 0; di < 3; di++)
                    for(int dj = 0; dj < 3; dj++)
                        for(int dk = 0; dk < 4; dk++)
                            conv2[i][j][k] += maxpool1[i+di][j+dj][dk] * weights_conv2[((di*3+dj)*4+dk)*8+k];
                conv2[i][j][k] += biases_conv2[k];
                conv2[i][j][k] = relu(conv2[i][j][k]);
            }

    // Second MaxPooling layer: input is 4x4x8, pool size is 2
    // It results in a 2x2x8 output
    float maxpool2[2][2][8];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++) {
                maxpool2[i][j][k] = 0;
                for(int di = 0; di < 2; di++)
                    for(int dj = 0; dj < 2; dj++)
                        maxpool2[i][j][k] = fmaxf(maxpool2[i][j][k], conv2[i*2+di][j*2+dj][k]);
            }

    // Flatten layer: input is 2x2x8
    // It results in a 32-length 1D array
    float flatten[32];
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 8; k++)
                flatten[i*2*8 + j*8 + k] = maxpool2[i][j][k];

    // Dense layer: input is a 32-length 1D array, weights are 32x10
    // It results in a 10-length 1D array
    float dense[10];
    for(int i = 0; i < 10; i++) {
        dense[i] = 0;
        for(int j = 0; j < 32; j++)
            dense[i] += flatten[j] * weights_dense2[j*10+i];
        dense[i] += biases_dense2[i];
    }

    // Softmax activation
    float* softmax_output = softmax(dense, 10);

    // One-hot output generation
    int max_index = 0;
    for (int i = 1; i < 10; ++i) {
        if (softmax_output[i] > softmax_output[max_index]) {
            max_index = i;
        }
    }

    // Set all elements to zero
    for (int i = 0; i < 10; ++i) {
        one_hot_output[i] = 0;
    }

    // Set the element at max_index to 1
    one_hot_output[max_index] = 1;

    // Print the output
    printf("C forward function label = %d\n", max_index);
    return max_index;
}


int main() {
    int one_Hot_output[10];
    ///////////////////////////////////////////////////////////////////////////

    FILE *file;
    float images[NUM_IMAGES][IMAGE_SIZE];
    int labels[NUM_IMAGES];
    int out_forward;

    file = fopen("test_images.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open image file.\n");
        return 1;
    }

    for (int i = 0; i < NUM_IMAGES; ++i) {
        fread(images[i], sizeof(float), IMAGE_SIZE, file);
    }

    fclose(file);

    file = fopen("test_labels.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open label file.\n");
        return 1;
    }

    fread(labels, sizeof(int), NUM_IMAGES, file);

    fclose(file);

    printf("Loaded %d images and labels.\n", NUM_IMAGES);


    ////////////////////////////////////////////////////////////////////////////
/*
    file = fopen("test_images.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open file.\n");
        return 1;
    }

    fread(single_image, sizeof(float), 28*28*1, file);

    printf("Single image declaration finih");

    
    file = fopen("train_labels.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open file.\n");
        return 1;
    }

    fread(&test_label, sizeof(int),1, file);

    printf("Label image declaration finih\n\n");
*/
    // Load the weights and biases from the binary files
    load_weights_biases();

    // Assume here that you have loaded a MNIST image into the 'image' array
    float image[28*28];

    // Call the forward pass function
    out_forward = forward_pass(image,one_Hot_output);
    printf("Test label = %d",labels);
    return 0;
}

## ASSISTANT
Sure, from the provided code, it seems that you are interested in checking the accuracy of the forward pass against a provided label. To do this, we can simply compare the output of the forward pass (which is the predicted label) with the actual label for each image. We can then count the number of correct predictions and divide by the total number of images to calculate the accuracy of the model. Here is a modification of your main function to do just that:
```c
int main() {
    int one_Hot_output[10];
    FILE *file;
    float images[NUM_IMAGES][IMAGE_SIZE];
    int labels[NUM_IMAGES];
    int out_forward;
    int correct_predictions = 0;  // Counts the number of correct predictions

    // Load the images
    file = fopen("test_images.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open image file.\n");
        return 1;
    }

    for (int i = 0; i < NUM_IMAGES; ++i) {
        fread(images[i], sizeof(float), IMAGE_SIZE, file);
    }
    fclose(file);

    // Load the labels
    file = fopen("test_labels.bin", "rb");
    if (file == NULL) {
        printf("Error: Unable to open label file.\n");
        return 1;
    }
    fread(labels, sizeof(int), NUM_IMAGES, file);
    fclose(file);

    printf("Loaded %d images and labels.\n", NUM_IMAGES);

    // Load the weights and biases from the binary files
    load_weights_biases();

    // For each image
    for (int i = 0; i < NUM_IMAGES; ++i) {
        // Call the forward pass function
        out_forward = forward_pass(images[i], one_Hot_output);

        printf("Predicted label = %d, Actual label = %d\n", out_forward, labels[i]);

        // If the predicted label matches the actual label, increment the count of correct predictions
        if (out_forward == labels[i]) {
            ++correct_predictions;
        }
    }

    // Calculate the accuracy
    float accuracy = ((float)correct_predictions / NUM_IMAGES) * 100.0f;

    printf("Accuracy = %.2f%%\n", accuracy);

    return 0;
}

```
In this code, we have added a counter variable correct_predictions to keep track of the number of correctly predicted labels. This counter is incremented whenever the output from the forward_pass function equals the actual label. Finally, we calculate and print the accuracy by dividing the number of correct predictions by the total number of images.
