{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Replace 'filename.csv' with the actual file path of your dataset\n",
        "df = pd.read_csv('mnist_train.csv')\n",
        "\n",
        "# Extract labels (first column)\n",
        "train_labels = df.iloc[:, 0].values\n",
        "\n",
        "# Extract pixel values and reshape them into 28x28 images\n",
        "train_images = df.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
        "\n",
        "\n",
        "\n",
        "# Replace 'filename.csv' with the actual file path of your dataset\n",
        "df2 = pd.read_csv('mnist_test.csv')\n",
        "\n",
        "# Extract labels (first column)\n",
        "test_labels = df2.iloc[:, 0].values\n",
        "\n",
        "# Extract pixel values and reshape them into 28x28 images\n",
        "test_images = df2.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
        "\n",
        "train_images = train_images.astype('float16')\n",
        "test_images = test_images.astype('float16')\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "print(test_images.dtype)\n",
        "print(train_images.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJqJEmKnC1N",
        "outputId": "f08a5ecd-6d5f-43dd-e301-bca8a667e19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float16\n",
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-edeL_t_sYXe",
        "outputId": "c385f274-21e1-4f97-a1c2-3bfa7a9b5b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 19s 4ms/step - loss: inf - accuracy: 0.4944\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5972 - accuracy: 0.8960\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4250 - accuracy: 0.9468\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3406 - accuracy: 0.9678\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2866 - accuracy: 0.9766\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2507 - accuracy: 0.9810\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2274 - accuracy: 0.9849\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2070 - accuracy: 0.9883\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1918 - accuracy: 0.9888\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1807 - accuracy: 0.9917\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1708 - accuracy: 0.9902\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1655 - accuracy: 0.9917\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1572 - accuracy: 0.9932\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1526 - accuracy: 0.9922\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1484 - accuracy: 0.9932\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1455 - accuracy: 0.9937\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1420 - accuracy: 0.9941\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1378 - accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1365 - accuracy: 0.9941\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1355 - accuracy: 0.9946\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1305 - accuracy: 0.9951\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1294 - accuracy: 0.9951\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1248 - accuracy: 0.9946\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1245 - accuracy: 0.9951\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1215 - accuracy: 0.9956\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1215 - accuracy: 0.9951\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1185 - accuracy: 0.9951\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9951\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1172 - accuracy: 0.9946\n",
            "313/313 - 1s - loss: 0.1164 - accuracy: 0.9727 - 913ms/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Enable mixed precision\n",
        "from tensorflow.keras.mixed_precision import global_policy, set_global_policy\n",
        "policy = tf.keras.mixed_precision.Policy('float16')\n",
        "set_global_policy(policy)\n",
        "\n",
        "# Load MNIST dataset\n",
        "\"\"\"(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\"\"\"\n",
        "\n",
        "# Reshape the images\n",
        "\"\"\"train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\"\"\"\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "\n",
        "\n",
        "# Convert the labels to categorical\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((4, 4)))\n",
        "model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, dtype='float16'))  # Ensure that the final layer has float32 dtype\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "model.fit(train_images, train_labels, epochs=30)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LT9_GLg2yx88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting weights and biases for each layer\n",
        "weights_conv1, biases_conv1 = model.layers[0].get_weights()\n",
        "weights_conv2, biases_conv2 = model.layers[2].get_weights()\n",
        "\"\"\"weights_conv3, biases_conv3 = model.layers[4].get_weights()\n",
        "weights_dense1, biases_dense1 = model.layers[5].get_weights()  # Corrected index\"\"\"\n",
        "weights_dense2, biases_dense2 = model.layers[5].get_weights()  # Corrected index\n",
        "\n",
        "print(weights_conv1.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRQS7Lor2ICL",
        "outputId": "de8e8868-7b9f-494c-f1fd-83db75dbdc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Now you can use these weights and biases for your custom forward function\n",
        "# Save weights and biases to .npy files\n",
        "np.save('weights_conv1.npy', weights_conv1)\n",
        "np.save('biases_conv1.npy', biases_conv1)\n",
        "np.save('weights_conv2.npy', weights_conv2)\n",
        "np.save('biases_conv2.npy', biases_conv2)\n",
        "\"\"\"np.save('weights_conv3.npy', weights_conv3)\n",
        "np.save('biases_conv3.npy', biases_conv3)\n",
        "np.save('weights_dense1.npy', weights_dense1)\n",
        "np.save('biases_dense1.npy', biases_dense1)\"\"\"\n",
        "np.save('weights_dense2.npy', weights_dense2)\n",
        "np.save('biases_dense2.npy', biases_dense2)\n",
        "\n",
        "weights_conv1.tofile('weights_conv1.bin')\n",
        "biases_conv1.tofile('biases_conv1.bin')\n",
        "weights_conv2.tofile('weights_conv2.bin')\n",
        "biases_conv2.tofile('biases_conv2.bin')\n",
        "weights_dense2.tofile('weights_dense2.bin')\n",
        "biases_dense2.tofile('biases_dense2.bin')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c4drbwxXs-0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights and biases from .npy files\n",
        "weights_conv1 = np.load('weights_conv1.npy')\n",
        "biases_conv1 = np.load('biases_conv1.npy')\n",
        "weights_conv2 = np.load('weights_conv2.npy')\n",
        "biases_conv2 = np.load('biases_conv2.npy')\n",
        "\"\"\"weights_conv3 = np.load('weights_conv3.npy')\n",
        "biases_conv3 = np.load('biases_conv3.npy')\n",
        "weights_dense1 = np.load('weights_dense1.npy')\n",
        "biases_dense1 = np.load('biases_dense1.npy')\"\"\"\n",
        "weights_dense2 = np.load('weights_dense2.npy')\n",
        "biases_dense2 = np.load('biases_dense2.npy')"
      ],
      "metadata": {
        "id": "W834Uy9uyIZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_conv1_2 = np.load('weights_conv1.npy')\n",
        "biases_conv1_2  = np.load('biases_conv1.npy')\n",
        "weights_conv2_2  = np.load('weights_conv2.npy')\n",
        "biases_conv2_2  = np.load('biases_conv2.npy')\n",
        "weights_dense2_2  = np.load('weights_dense2.npy')\n",
        "biases_dense2_2  = np.load('biases_dense2.npy')\n",
        "\n",
        "# Compare the weights and biases\n",
        "weights_conv1_are_equal = np.array_equal(weights_conv1, weights_conv1_2)\n",
        "biases_conv1_are_equal = np.array_equal(biases_conv1, biases_conv1_2)\n",
        "weights_conv2_are_equal = np.array_equal(weights_conv2, weights_conv2_2)\n",
        "biases_conv2_are_equal = np.array_equal(biases_conv2, biases_conv2_2)\n",
        "weights_dense2_are_equal = np.array_equal(weights_dense2, weights_dense2_2)\n",
        "biases_dense2_are_equal = np.array_equal(biases_dense2, biases_dense2_2)\n",
        "\n",
        "# Print the comparison results\n",
        "print('Weights_conv1 are equal:', weights_conv1_are_equal)\n",
        "print('Biases_conv1 are equal:', biases_conv1_are_equal)\n",
        "print('Weights_conv2 are equal:', weights_conv2_are_equal)\n",
        "print('Biases_conv2 are equal:', biases_conv2_are_equal)\n",
        "print('Weights_dense2 are equal:', weights_dense2_are_equal)\n",
        "print('Biases_dense2 are equal:', biases_dense2_are_equal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGtX00k4iZL",
        "outputId": "5c848ea3-7dbf-447d-8698-b27f7ba7e208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights_conv1 are equal: True\n",
            "Biases_conv1 are equal: True\n",
            "Weights_conv2 are equal: True\n",
            "Biases_conv2 are equal: True\n",
            "Weights_dense2 are equal: True\n",
            "Biases_dense2 are equal: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# define activation functions\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exps = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=-1, keepdims=True)\n",
        "\n",
        "# define forward pass functions\n",
        "def conv2d_forward(X, W, b):\n",
        "    # X - input, W - weights, b - bias\n",
        "    h_filter, w_filter, d_filter, n_filters = W.shape\n",
        "    h, w, d = X.shape\n",
        "    out = np.zeros((h - h_filter + 1, w - w_filter + 1, n_filters))\n",
        "    for i in range(h - h_filter + 1):\n",
        "        for j in range(w - w_filter + 1):\n",
        "            for k in range(n_filters):\n",
        "                out[i, j, k] = np.sum(X[i:i+h_filter, j:j+w_filter] * W[:, :, :, k]) + b[k]\n",
        "    return out\n",
        "\n",
        "def maxpool2d_forward(X, pool_size):\n",
        "    h, w, d = X.shape\n",
        "    h_out = h // pool_size\n",
        "    w_out = w // pool_size\n",
        "    out = np.zeros((h_out, w_out, d))\n",
        "    for i in range(h_out):\n",
        "        for j in range(w_out):\n",
        "            for k in range(d):\n",
        "                out[i, j, k] = np.max(X[i*pool_size:(i+1)*pool_size, j*pool_size:(j+1)*pool_size, k])\n",
        "    return out\n",
        "\n",
        "def flatten(X):\n",
        "    return X.flatten()\n",
        "\n",
        "def dense_forward(X, W, b):\n",
        "    return np.dot(W.T, X) + b\n",
        "\n"
      ],
      "metadata": {
        "id": "5-oQwLyisd32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming weights and biases have been loaded as mentioned before\n",
        "# Modify the forward function to take these parameters as arguments\n",
        "\n",
        "def forward(X, W_conv1, b_conv1, W_conv2, b_conv2, W_dense2, b_dense2):\n",
        "    out = conv2d_forward(X, W_conv1, b_conv1)\n",
        "    out = relu(out)\n",
        "    out = maxpool2d_forward(out, 4)\n",
        "    out = conv2d_forward(out, W_conv2, b_conv2)\n",
        "    out = relu(out)\n",
        "    out = maxpool2d_forward(out, 2)\n",
        "    \"\"\"   out = conv2d_forward(out, W_conv3, b_conv3)\n",
        "    out = relu(out)\n",
        "    out = maxpool2d_forward(out, 2)\n",
        "\n",
        "    out = dense_forward(out, W_dense1, b_dense1)\n",
        "    out = relu(out)\"\"\"\n",
        "    out = flatten(out)\n",
        "    out = dense_forward(out, W_dense2, b_dense2)\n",
        "    out = softmax(out)\n",
        "    return out\n",
        "\n",
        "# Call the function with a single image from the test dataset and the weights and biases\n",
        "\n",
        "image_index = 96\n",
        "single_image = test_images[image_index]  # assuming test_images is your test dataset\n",
        "\n",
        "# Ensure that the single image has the right shape (28, 28, 1)\n",
        "single_image = np.reshape(single_image, (28, 28, 1))\n",
        "\n",
        "output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_dense2, biases_dense2)\n",
        "\n",
        "print(np.argmax(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geLOw4HVtfLQ",
        "outputId": "75862339-4899-4323-d520-130b78687051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "print(\"Test image shape:\", test_images[image_index].shape)  # (28, 28)\n",
        "print(\"Test label:\", test_labels[image_index])  # The label (0 to 9)\n",
        "\n",
        "x = test_images[image_index]\n",
        "\n",
        "x = x.reshape(28, 28, 1)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you already have 'x' containing the image data\n",
        "\n",
        "# Reshape the image back to 28x28 (if necessary)\n",
        "if len(x.shape) == 3:\n",
        "    x = x.reshape(28, 28)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(x, cmap='gray')\n",
        "plt.axis('off')  # Turn off axis ticks and labels\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "1Y46WFMAuZ-V",
        "outputId": "a2f01159-1b56-413c-eb7e-3ee2878aef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test image shape: (28, 28)\n",
            "Test label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data() #%%This was doing before\n",
        "# iterate over the test set\n",
        "#for i in range(len(x_test)):\n",
        "\n",
        "for i in range(1000):\n",
        "    # prepare the input\n",
        "    x = test_images[i].astype(np.float16)\n",
        "\n",
        "    # Ensure that the single image has the right shape (28, 28, 1)\n",
        "    single_image = np.reshape(x, (28, 28, 1))\n",
        "\n",
        "    #output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_conv3, biases_conv3, weights_dense1, biases_dense1, weights_dense2, biases_dense2)\n",
        "    output = forward(single_image, weights_conv1, biases_conv1, weights_conv2, biases_conv2, weights_dense2, biases_dense2)\n",
        "\n",
        "    # Find the index of the maximum value\n",
        "    prediction = np.argmax(output)\n",
        "\n",
        "    # compare the prediction with the actual label\n",
        "    actual_label = np.argmax(test_labels[i])\n",
        "    #actual_label = test_labels[i]\n",
        "\n",
        "    if prediction == actual_label:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# calculate the accuracy\n",
        "accuracy = correct_predictions / 1000\n",
        "print(\"The accuracy of the forward_pass function is:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FelUwCUavMYG",
        "outputId": "27063ca9-6ffe-4715-b737-87ff0881b941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the forward_pass function is: 0.932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights_conv1.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXJbPwz2xkqM",
        "outputId": "d21e6946-fabc-4da1-cfe1-f19d777035e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float16\n"
          ]
        }
      ]
    }
  ]
}